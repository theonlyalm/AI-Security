### üìë Dumping a Database with an AI Chatbot

---

* **Severity:** üî¥ Critical
* **Target:** Internal AI Chatbot on a host target
* **Vulnerability Types:** Authentication Bypass, Excessive Agency (OWASP LLM08), and Insecure Output Handling (OWASP LLM02)

---

### üìñ Executive Summary

Researcher Kuldeep Pandya discovered a critical vulnerability in a healthcare-associated AI chatbot that allowed for **full database exfiltration** and **underlying filesystem access**. The attack began with a simple authentication bypass and escalated when the chatbot revealed it had the authority to execute raw SQL queries against its own backend database.

---

### üîì Phase 1: Discovery & Authentication Bypass

While performing reconnaissance on a Synack host target, the researcher used `aquatone` to screenshot active HTTP services. He discovered a login page that appeared to be protected but lacked any actual validation logic.

* **The Flaw:** Entering "admin" or even a **random string** into the username field granted a valid authentication cookie.
* **Result:** Immediate, unauthorized access to the internal AI chatbot interface.

---

### üîç Phase 2: Enumerating Permissions

Rather than using complex payloads, the researcher simply asked the bot about its capabilities. The bot's response was surprisingly transparent:

> "I can help you query employee data... I can run SQL Queries."

To verify this "Excessive Agency," the researcher tested a benign query:
`SELECT * FROM Department LIMIT 10;`

The bot executed the command and returned the data, confirming it had a **direct line of execution** to the database without a middle-tier sanitization layer.

---

### üì• Phase 3: Dumping the Database & Filesystem

With a direct SQL interface established, the researcher proceeded to map the environment:

1. **Identify User Context:**
```sql
SELECT CURRENT_USER;

```


* **Result:** The bot was running as the `postgres` superuser.


2. **List Tables:**
The researcher identified a sensitive table named `person`.
3. **Data Exfiltration:**
By querying `SELECT * FROM person LIMIT 10;`, the researcher was able to dump PII (Personally Identifiable Information).
4. **Filesystem Access:**
Because the database was PostgreSQL and the user was a superuser, the researcher was able to list the directory contents of the server:
```sql
SELECT pg_ls_dir('./');

```



---

### üõ°Ô∏è Remediation & Recommendations

Based on the **OWASP Top 10 for LLM Applications**, this vulnerability highlights the danger of "Excessive Agency"‚Äîgiving an AI tool more permissions than necessary to perform its task.

| Strategy | Implementation |
| --- | --- |
| **API Mediation** | Never give an LLM raw database credentials. Use a secure API gateway (middleware) that only allows specific, pre-defined requests. |
| **Least Privilege** | Ensure the database user used by the chatbot has `READ-ONLY` access to specific tables, not `postgres` superuser status. |
| **Output Sanitization** | Implement a validation layer to inspect SQL queries generated by the LLM before they are executed. |
| **Parameterized Queries** | Use bound parameters to ensure user-supplied data cannot alter the intent of the SQL command. |
